{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "data_train = open(\"data_train.txt\")\n",
    "label_train = open(\"labels_train_original.txt\")\n",
    "data_test = open(\"data_valid.txt\")\n",
    "label_test = open(\"labels_valid_original.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Text Preprocessing \n",
    "In order to perform machine learning on text documents, we first need to turn the text content into numerical feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 replace text labels in training set to numerical labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace = {\n",
    "    'News':0,\n",
    "    'Classifieds':2,\n",
    "    'Opinion':1,\n",
    "    'Features':3\n",
    "}\n",
    "Y_train = [replace[y.rstrip('\\n')] for y in label_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Tokenizing the artical in training set\n",
    "CountVectorizer() builds a dictionary of features and transforms documents to feature vectors.\n",
    "The index value of a word in the vocabulary is linked to its frequency in the whole training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 38749)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(data_train)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'front': 14711, 'in': 17827, 'of': 24546, 'sign': 31683, 'the': 34753}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(count_vect.vocabulary_.items())[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Term Frequency times Inverse Document Frequency\n",
    "The goal of using tf-idf instead of the raw frequencies of occurrence of a token in a given document is to scale down the impact of tokens that occur very frequently in a given corpus and that are hence empirically less informative than features that occur in a small fraction of the training corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 38749)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Do the same things to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test = [replace[y.rstrip('\\n')] for y in label_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = list()\n",
    "for line in data_test:\n",
    "    line = str(line.rstrip())\n",
    "    X_test.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_counts = count_vect.transform(X_test)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.6, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_NB = MultinomialNB(alpha=0.6).fit(X_train_tfidf, Y_train)\n",
    "clf_NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_train_predicted = clf_NB.predict(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Training Set:\n",
      " [[466  13   9  16]\n",
      " [  9 465   4   7]\n",
      " [ 19   7 460  37]\n",
      " [ 22  26   1 439]]\n",
      "Accuracy Rate of Training Set:\n",
      " 0.915\n"
     ]
    }
   ],
   "source": [
    "NB_train_CM = confusion_matrix(Y_train, NB_train_predicted)\n",
    "print('Confusion Matrix of Training Set:\\n',NB_train_CM)\n",
    "print('Accuracy Rate of Training Set:\\n',\n",
    "      (NB_train_CM[0][0]+NB_train_CM[1][1]+NB_train_CM[2][2]+NB_train_CM[3][3])/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NB_test_predicted = clf_NB.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Test Set:\n",
      " [[314  40  65  93]\n",
      " [ 25 414  16  52]\n",
      " [ 58  22 297  93]\n",
      " [ 52  82  80 297]]\n",
      "Accuracy Rate of Test Set:\n",
      " 0.661\n"
     ]
    }
   ],
   "source": [
    "NB_test_CM = confusion_matrix(Y_test, NB_test_predicted)\n",
    "print('Confusion Matrix of Test Set:\\n',NB_test_CM)\n",
    "print('Accuracy Rate of Test Set:\\n',(NB_test_CM[0][0]+NB_test_CM[1][1]+NB_test_CM[2][2]+NB_test_CM[3][3])/2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=75, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_LR = LogisticRegression(random_state=0,C=75).fit(X_train_tfidf, Y_train)\n",
    "clf_LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_train_predicted = clf_LR.predict(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Training Set:\n",
      " [[504   0   0   0]\n",
      " [  0 485   0   0]\n",
      " [  0   0 523   0]\n",
      " [  0   0   0 488]]\n",
      "Accuracy Rate of Training Set:\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "LR_train_CM = confusion_matrix(Y_train, LR_train_predicted)\n",
    "print('Confusion Matrix of Training Set:\\n',LR_train_CM)\n",
    "print('Accuracy Rate of Training Set:\\n',\n",
    "      (LR_train_CM[0][0]+LR_train_CM[1][1]+LR_train_CM[2][2]+LR_train_CM[3][3])/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LR_test_predicted = clf_LR.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Test Set:\n",
      " [[328  41  67  76]\n",
      " [ 16 438  20  33]\n",
      " [ 41  14 350  65]\n",
      " [ 60  77  71 303]]\n",
      "Accuracy Rate of Test Set:\n",
      " 0.7095\n"
     ]
    }
   ],
   "source": [
    "LR_test_CM = confusion_matrix(Y_test, LR_test_predicted)\n",
    "print('Confusion Matrix of Test Set:\\n',LR_test_CM)\n",
    "print('Accuracy Rate of Test Set:\\n',(LR_test_CM[0][0]+LR_test_CM[1][1]+LR_test_CM[2][2]+LR_test_CM[3][3])/2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 SVM ( SVC with Linear Kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=2, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf_svm1 = svm.SVC(decision_function_shape='ovo',kernel='linear',C=2).fit(X_train_tfidf, Y_train)\n",
    "clf_svm1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm1_train_predicted = clf_svm1.predict(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Training Set:\n",
      " [[503   0   1   0]\n",
      " [  0 485   0   0]\n",
      " [  0   0 523   0]\n",
      " [  3   0   0 485]]\n",
      "Accuracy Rate of Training Set:\n",
      " 0.998\n"
     ]
    }
   ],
   "source": [
    "svm1_train_CM = confusion_matrix(Y_train, svm1_train_predicted)\n",
    "print('Confusion Matrix of Training Set:\\n',svm1_train_CM)\n",
    "print('Accuracy Rate of Training Set:\\n',\n",
    "      (svm1_train_CM[0][0]+svm1_train_CM[1][1]+svm1_train_CM[2][2]+svm1_train_CM[3][3])/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm1_test_predicted = clf_svm1.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Test Set:\n",
      " [[324  37  67  84]\n",
      " [ 15 435  20  37]\n",
      " [ 44  13 343  70]\n",
      " [ 57  69  70 315]]\n",
      "Accuracy Rate of Test Set:\n",
      " 0.7085\n"
     ]
    }
   ],
   "source": [
    "svm1_test_CM = confusion_matrix(Y_test, svm1_test_predicted)\n",
    "print('Confusion Matrix of Test Set:\\n',svm1_test_CM)\n",
    "print('Accuracy Rate of Test Set:\\n',(svm1_test_CM[0][0]+svm1_test_CM[1][1]+svm1_test_CM[2][2]+svm1_test_CM[3][3])/2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 SVM ( Linear SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm2 = svm.LinearSVC().fit(X_train_tfidf, Y_train)\n",
    "clf_svm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm2_train_predicted = clf_svm2.predict(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Training Set:\n",
      " [[504   0   0   0]\n",
      " [  0 485   0   0]\n",
      " [  0   0 523   0]\n",
      " [  1   0   0 487]]\n",
      "Accuracy Rate of Training Set:\n",
      " 0.9995\n"
     ]
    }
   ],
   "source": [
    "svm2_train_CM = confusion_matrix(Y_train, svm2_train_predicted)\n",
    "print('Confusion Matrix of Training Set:\\n',svm2_train_CM)\n",
    "print('Accuracy Rate of Training Set:\\n',\n",
    "      (svm2_train_CM[0][0]+svm2_train_CM[1][1]+svm2_train_CM[2][2]+svm2_train_CM[3][3])/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm2_test_predicted = clf_svm2.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Test Set:\n",
      " [[331  43  65  73]\n",
      " [ 15 443  19  30]\n",
      " [ 42  17 341  70]\n",
      " [ 55  81  71 304]]\n",
      "Accuracy Rate of Test Set:\n",
      " 0.7095\n"
     ]
    }
   ],
   "source": [
    "svm2_test_CM = confusion_matrix(Y_test, svm2_test_predicted)\n",
    "print('Confusion Matrix of Test Set:\\n',svm2_test_CM)\n",
    "print('Accuracy Rate of Test Set:\\n',(svm2_test_CM[0][0]+svm2_test_CM[1][1]+svm2_test_CM[2][2]+svm2_test_CM[3][3])/2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=15,weights='distance').fit(X_train_tfidf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neigh_predicted = neigh.predict(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Training Set:\n",
      " [[504   0   0   0]\n",
      " [  0 485   0   0]\n",
      " [  0   0 523   0]\n",
      " [  0   0   0 488]]\n",
      "Accuracy Rate of Training Set:\n",
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "neigh_train_CM = confusion_matrix(Y_train, neigh_predicted)\n",
    "print('Confusion Matrix of Training Set:\\n',neigh_train_CM)\n",
    "print('Accuracy Rate of Training Set:\\n',\n",
    "      (neigh_train_CM[0][0]+neigh_train_CM[1][1]+neigh_train_CM[2][2]+neigh_train_CM[3][3])/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neigh_test_predicted = neigh.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of Test Set:\n",
      " [[299  31 135  47]\n",
      " [ 38 274 127  68]\n",
      " [ 43  19 365  43]\n",
      " [ 78  36 177 220]]\n",
      "Accuracy Rate of Test Set:\n",
      " 0.579\n"
     ]
    }
   ],
   "source": [
    "neigh_test_CM = confusion_matrix(Y_test, neigh_test_predicted)\n",
    "print('Confusion Matrix of Test Set:\\n',neigh_test_CM)\n",
    "print('Accuracy Rate of Test Set:\\n',\n",
    "      (neigh_test_CM[0][0]+neigh_test_CM[1][1]+neigh_test_CM[2][2]+neigh_test_CM[3][3])/2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
